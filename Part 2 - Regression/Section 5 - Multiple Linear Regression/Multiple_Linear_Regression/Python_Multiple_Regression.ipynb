{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions of linear regression\n",
    "1. Linearity\n",
    "2. Homogeneity of variance\n",
    "3. Multivariate normality\n",
    "4. Independence of errors\n",
    "5. Lack of multicollinearity (i.e., each vector is not a linear combination of other vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Elimination\n",
    "\n",
    "1. Select a significance level to stay in the model (sig= .05)\n",
    "2. Fit the full model with all possible predictors\n",
    "3. Consider the predictor with the highest p-value. If p > .05, go to step4.\n",
    "4. Remove the predictor\n",
    "5. Fit model without that variable (rebuild the model, coefficient will be different)\n",
    "6. Repeat 3-5\n",
    "7. When p < .05, the model is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection\n",
    "\n",
    "1. Select a significance level to enter the model (sig= .05)\n",
    "2. Fit all simple regression models y ~ $x_{n}$, select the one with the lowest p-value\n",
    "3. Keep this variable and fit all possible models with one extra predictor added \n",
    "4. Consider the predictor with the lowest p-value. If p < .05, repeat 3-4\n",
    "5. When p > .05, keep the previous model and your model is ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Elimination (Step-wise Regression)\n",
    "\n",
    "1. Select a significance level to enter and to stay in the model (e.g., sig_enter =.05, sig_stay= .05)\n",
    "2. Perform the next step of Forward Selection (new variable must have p < sig_enter to enter)\n",
    "3. Perform ALL steps of Backward Elimination (old variable must have p < sig_stay to stay)\n",
    "4. Repeat 2-3\n",
    "5. No new variables can enter and no old variables can exit, your model is ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All possible Models\n",
    "\n",
    "1. Select a criterion of goofness of fit (e.g., Akaike criterion)\n",
    "2. Construct all possible regression models: $2^{N} - 1$ total combinations\n",
    "3. Select the one with the best criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 2],\n",
       "       [162597.7, 151377.59, 443898.53, 0],\n",
       "       [153441.51, 101145.55, 407934.54, 1],\n",
       "       [144372.41, 118671.85, 383199.62, 2],\n",
       "       [142107.34, 91391.77, 366168.42, 1],\n",
       "       [131876.9, 99814.71, 362861.36, 2],\n",
       "       [134615.46, 147198.87, 127716.82, 0],\n",
       "       [130298.13, 145530.06, 323876.68, 1],\n",
       "       [120542.52, 148718.95, 311613.29, 2],\n",
       "       [123334.88, 108679.17, 304981.62, 0],\n",
       "       [101913.08, 110594.11, 229160.95, 1],\n",
       "       [100671.96, 91790.61, 249744.55, 0],\n",
       "       [93863.75, 127320.38, 249839.44, 1],\n",
       "       [91992.39, 135495.07, 252664.93, 0],\n",
       "       [119943.24, 156547.42, 256512.92, 1],\n",
       "       [114523.61, 122616.84, 261776.23, 2],\n",
       "       [78013.11, 121597.55, 264346.06, 0],\n",
       "       [94657.16, 145077.58, 282574.31, 2],\n",
       "       [91749.16, 114175.79, 294919.57, 1],\n",
       "       [86419.7, 153514.11, 0.0, 2],\n",
       "       [76253.86, 113867.3, 298664.47, 0],\n",
       "       [78389.47, 153773.43, 299737.29, 2],\n",
       "       [73994.56, 122782.75, 303319.26, 1],\n",
       "       [67532.53, 105751.03, 304768.73, 1],\n",
       "       [77044.01, 99281.34, 140574.81, 2],\n",
       "       [64664.71, 139553.16, 137962.62, 0],\n",
       "       [75328.87, 144135.98, 134050.07, 1],\n",
       "       [72107.6, 127864.55, 353183.81, 2],\n",
       "       [66051.52, 182645.56, 118148.2, 1],\n",
       "       [65605.48, 153032.06, 107138.38, 2],\n",
       "       [61994.48, 115641.28, 91131.24, 1],\n",
       "       [61136.38, 152701.92, 88218.23, 2],\n",
       "       [63408.86, 129219.61, 46085.25, 0],\n",
       "       [55493.95, 103057.49, 214634.81, 1],\n",
       "       [46426.07, 157693.92, 210797.67, 0],\n",
       "       [46014.02, 85047.44, 205517.64, 2],\n",
       "       [28663.76, 127056.21, 201126.82, 1],\n",
       "       [44069.95, 51283.14, 197029.42, 0],\n",
       "       [20229.59, 65947.93, 185265.1, 2],\n",
       "       [38558.51, 82982.09, 174999.3, 0],\n",
       "       [28754.33, 118546.05, 172795.67, 0],\n",
       "       [27892.92, 84710.77, 164470.71, 1],\n",
       "       [23640.93, 96189.63, 148001.11, 0],\n",
       "       [15505.73, 127382.3, 35534.17, 2],\n",
       "       [22177.74, 154806.14, 28334.72, 0],\n",
       "       [1000.23, 124153.04, 1903.93, 2],\n",
       "       [1315.46, 115816.21, 297114.46, 1],\n",
       "       [0.0, 135426.92, 0.0, 0],\n",
       "       [542.05, 51743.15, 0.0, 2],\n",
       "       [0.0, 116983.8, 45173.06, 0]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "# label the selected column numerically\n",
    "X[:, -1] = labelencoder_X.fit_transform(X[:, -1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [-1])\n",
    "# dummy code the selected column\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.  ,      1.  , 165349.2 , 136897.8 , 471784.1 ],\n",
       "       [     0.  ,      0.  , 162597.7 , 151377.59, 443898.53],\n",
       "       [     1.  ,      0.  , 153441.51, 101145.55, 407934.54],\n",
       "       [     0.  ,      1.  , 144372.41, 118671.85, 383199.62],\n",
       "       [     1.  ,      0.  , 142107.34,  91391.77, 366168.42],\n",
       "       [     0.  ,      1.  , 131876.9 ,  99814.71, 362861.36],\n",
       "       [     0.  ,      0.  , 134615.46, 147198.87, 127716.82],\n",
       "       [     1.  ,      0.  , 130298.13, 145530.06, 323876.68],\n",
       "       [     0.  ,      1.  , 120542.52, 148718.95, 311613.29],\n",
       "       [     0.  ,      0.  , 123334.88, 108679.17, 304981.62],\n",
       "       [     1.  ,      0.  , 101913.08, 110594.11, 229160.95],\n",
       "       [     0.  ,      0.  , 100671.96,  91790.61, 249744.55],\n",
       "       [     1.  ,      0.  ,  93863.75, 127320.38, 249839.44],\n",
       "       [     0.  ,      0.  ,  91992.39, 135495.07, 252664.93],\n",
       "       [     1.  ,      0.  , 119943.24, 156547.42, 256512.92],\n",
       "       [     0.  ,      1.  , 114523.61, 122616.84, 261776.23],\n",
       "       [     0.  ,      0.  ,  78013.11, 121597.55, 264346.06],\n",
       "       [     0.  ,      1.  ,  94657.16, 145077.58, 282574.31],\n",
       "       [     1.  ,      0.  ,  91749.16, 114175.79, 294919.57],\n",
       "       [     0.  ,      1.  ,  86419.7 , 153514.11,      0.  ],\n",
       "       [     0.  ,      0.  ,  76253.86, 113867.3 , 298664.47],\n",
       "       [     0.  ,      1.  ,  78389.47, 153773.43, 299737.29],\n",
       "       [     1.  ,      0.  ,  73994.56, 122782.75, 303319.26],\n",
       "       [     1.  ,      0.  ,  67532.53, 105751.03, 304768.73],\n",
       "       [     0.  ,      1.  ,  77044.01,  99281.34, 140574.81],\n",
       "       [     0.  ,      0.  ,  64664.71, 139553.16, 137962.62],\n",
       "       [     1.  ,      0.  ,  75328.87, 144135.98, 134050.07],\n",
       "       [     0.  ,      1.  ,  72107.6 , 127864.55, 353183.81],\n",
       "       [     1.  ,      0.  ,  66051.52, 182645.56, 118148.2 ],\n",
       "       [     0.  ,      1.  ,  65605.48, 153032.06, 107138.38],\n",
       "       [     1.  ,      0.  ,  61994.48, 115641.28,  91131.24],\n",
       "       [     0.  ,      1.  ,  61136.38, 152701.92,  88218.23],\n",
       "       [     0.  ,      0.  ,  63408.86, 129219.61,  46085.25],\n",
       "       [     1.  ,      0.  ,  55493.95, 103057.49, 214634.81],\n",
       "       [     0.  ,      0.  ,  46426.07, 157693.92, 210797.67],\n",
       "       [     0.  ,      1.  ,  46014.02,  85047.44, 205517.64],\n",
       "       [     1.  ,      0.  ,  28663.76, 127056.21, 201126.82],\n",
       "       [     0.  ,      0.  ,  44069.95,  51283.14, 197029.42],\n",
       "       [     0.  ,      1.  ,  20229.59,  65947.93, 185265.1 ],\n",
       "       [     0.  ,      0.  ,  38558.51,  82982.09, 174999.3 ],\n",
       "       [     0.  ,      0.  ,  28754.33, 118546.05, 172795.67],\n",
       "       [     1.  ,      0.  ,  27892.92,  84710.77, 164470.71],\n",
       "       [     0.  ,      0.  ,  23640.93,  96189.63, 148001.11],\n",
       "       [     0.  ,      1.  ,  15505.73, 127382.3 ,  35534.17],\n",
       "       [     0.  ,      0.  ,  22177.74, 154806.14,  28334.72],\n",
       "       [     0.  ,      1.  ,   1000.23, 124153.04,   1903.93],\n",
       "       [     1.  ,      0.  ,   1315.46, 115816.21, 297114.46],\n",
       "       [     0.  ,      0.  ,      0.  , 135426.92,      0.  ],\n",
       "       [     0.  ,      1.  ,    542.05,  51743.15,      0.  ],\n",
       "       [     0.  ,      0.  ,      0.  , 116983.8 ,  45173.06]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVOID dummy variable trap. But the regression library we use will take care of this\n",
    "X= X[:, 1:]\n",
    "\n",
    "#Format numpy output, supress scientific notation\n",
    "# np.set_printoptions(precision=4,\n",
    "#                        threshold=10000,\n",
    "#                        linewidth=150,\n",
    "#                         suppress=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit multiple regression model to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor= LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.2016, 132582.2776, 132447.7385,  71976.0985, 178537.4822, 116161.2423,  67851.6921,  98791.7337, 113969.4353, 167921.0657])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the test set results\n",
    "y_pred= regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,  81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1.  ,      0.  ,      1.  , 165349.2 , 136897.8 , 471784.1 ],\n",
       "       [     1.  ,      0.  ,      0.  , 162597.7 , 151377.59, 443898.53],\n",
       "       [     1.  ,      1.  ,      0.  , 153441.51, 101145.55, 407934.54],\n",
       "       [     1.  ,      0.  ,      1.  , 144372.41, 118671.85, 383199.62],\n",
       "       [     1.  ,      1.  ,      0.  , 142107.34,  91391.77, 366168.42],\n",
       "       [     1.  ,      0.  ,      1.  , 131876.9 ,  99814.71, 362861.36],\n",
       "       [     1.  ,      0.  ,      0.  , 134615.46, 147198.87, 127716.82],\n",
       "       [     1.  ,      1.  ,      0.  , 130298.13, 145530.06, 323876.68],\n",
       "       [     1.  ,      0.  ,      1.  , 120542.52, 148718.95, 311613.29],\n",
       "       [     1.  ,      0.  ,      0.  , 123334.88, 108679.17, 304981.62],\n",
       "       [     1.  ,      1.  ,      0.  , 101913.08, 110594.11, 229160.95],\n",
       "       [     1.  ,      0.  ,      0.  , 100671.96,  91790.61, 249744.55],\n",
       "       [     1.  ,      1.  ,      0.  ,  93863.75, 127320.38, 249839.44],\n",
       "       [     1.  ,      0.  ,      0.  ,  91992.39, 135495.07, 252664.93],\n",
       "       [     1.  ,      1.  ,      0.  , 119943.24, 156547.42, 256512.92],\n",
       "       [     1.  ,      0.  ,      1.  , 114523.61, 122616.84, 261776.23],\n",
       "       [     1.  ,      0.  ,      0.  ,  78013.11, 121597.55, 264346.06],\n",
       "       [     1.  ,      0.  ,      1.  ,  94657.16, 145077.58, 282574.31],\n",
       "       [     1.  ,      1.  ,      0.  ,  91749.16, 114175.79, 294919.57],\n",
       "       [     1.  ,      0.  ,      1.  ,  86419.7 , 153514.11,      0.  ],\n",
       "       [     1.  ,      0.  ,      0.  ,  76253.86, 113867.3 , 298664.47],\n",
       "       [     1.  ,      0.  ,      1.  ,  78389.47, 153773.43, 299737.29],\n",
       "       [     1.  ,      1.  ,      0.  ,  73994.56, 122782.75, 303319.26],\n",
       "       [     1.  ,      1.  ,      0.  ,  67532.53, 105751.03, 304768.73],\n",
       "       [     1.  ,      0.  ,      1.  ,  77044.01,  99281.34, 140574.81],\n",
       "       [     1.  ,      0.  ,      0.  ,  64664.71, 139553.16, 137962.62],\n",
       "       [     1.  ,      1.  ,      0.  ,  75328.87, 144135.98, 134050.07],\n",
       "       [     1.  ,      0.  ,      1.  ,  72107.6 , 127864.55, 353183.81],\n",
       "       [     1.  ,      1.  ,      0.  ,  66051.52, 182645.56, 118148.2 ],\n",
       "       [     1.  ,      0.  ,      1.  ,  65605.48, 153032.06, 107138.38],\n",
       "       [     1.  ,      1.  ,      0.  ,  61994.48, 115641.28,  91131.24],\n",
       "       [     1.  ,      0.  ,      1.  ,  61136.38, 152701.92,  88218.23],\n",
       "       [     1.  ,      0.  ,      0.  ,  63408.86, 129219.61,  46085.25],\n",
       "       [     1.  ,      1.  ,      0.  ,  55493.95, 103057.49, 214634.81],\n",
       "       [     1.  ,      0.  ,      0.  ,  46426.07, 157693.92, 210797.67],\n",
       "       [     1.  ,      0.  ,      1.  ,  46014.02,  85047.44, 205517.64],\n",
       "       [     1.  ,      1.  ,      0.  ,  28663.76, 127056.21, 201126.82],\n",
       "       [     1.  ,      0.  ,      0.  ,  44069.95,  51283.14, 197029.42],\n",
       "       [     1.  ,      0.  ,      1.  ,  20229.59,  65947.93, 185265.1 ],\n",
       "       [     1.  ,      0.  ,      0.  ,  38558.51,  82982.09, 174999.3 ],\n",
       "       [     1.  ,      0.  ,      0.  ,  28754.33, 118546.05, 172795.67],\n",
       "       [     1.  ,      1.  ,      0.  ,  27892.92,  84710.77, 164470.71],\n",
       "       [     1.  ,      0.  ,      0.  ,  23640.93,  96189.63, 148001.11],\n",
       "       [     1.  ,      0.  ,      1.  ,  15505.73, 127382.3 ,  35534.17],\n",
       "       [     1.  ,      0.  ,      0.  ,  22177.74, 154806.14,  28334.72],\n",
       "       [     1.  ,      0.  ,      1.  ,   1000.23, 124153.04,   1903.93],\n",
       "       [     1.  ,      1.  ,      0.  ,   1315.46, 115816.21, 297114.46],\n",
       "       [     1.  ,      0.  ,      0.  ,      0.  , 135426.92,      0.  ],\n",
       "       [     1.  ,      0.  ,      1.  ,    542.05,  51743.15,      0.  ],\n",
       "       [     1.  ,      0.  ,      0.  ,      0.  , 116983.8 ,  45173.06]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "#statsmodels requires users to add column x0 = 1 for intercept\n",
    "X = np.append(arr= np.ones((50, 1)).astype(int), values= X, axis= 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal model\n",
    "X_opt= X[:, [0,1,2,3,4,5]]\n",
    "# create object in OLS(ordinary least squares) class\n",
    "regressor_OLS= sm.OLS(endog= y, exog= X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:01:46</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Wed, 20 Feb 2019   Prob (F-statistic):           1.34e-27\n",
       "Time:                        12:01:46   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:01:55</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Wed, 20 Feb 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        12:01:55   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt= X[:, [0,3,5]]\n",
    "regressor_OLS= sm.OLS(endog= y, exog= X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1.  , 165349.2 , 471784.1 ],\n",
       "       [     1.  , 162597.7 , 443898.53],\n",
       "       [     1.  , 153441.51, 407934.54],\n",
       "       [     1.  , 144372.41, 383199.62],\n",
       "       [     1.  , 142107.34, 366168.42],\n",
       "       [     1.  , 131876.9 , 362861.36],\n",
       "       [     1.  , 134615.46, 127716.82],\n",
       "       [     1.  , 130298.13, 323876.68],\n",
       "       [     1.  , 120542.52, 311613.29],\n",
       "       [     1.  , 123334.88, 304981.62],\n",
       "       [     1.  , 101913.08, 229160.95],\n",
       "       [     1.  , 100671.96, 249744.55],\n",
       "       [     1.  ,  93863.75, 249839.44],\n",
       "       [     1.  ,  91992.39, 252664.93],\n",
       "       [     1.  , 119943.24, 256512.92],\n",
       "       [     1.  , 114523.61, 261776.23],\n",
       "       [     1.  ,  78013.11, 264346.06],\n",
       "       [     1.  ,  94657.16, 282574.31],\n",
       "       [     1.  ,  91749.16, 294919.57],\n",
       "       [     1.  ,  86419.7 ,      0.  ],\n",
       "       [     1.  ,  76253.86, 298664.47],\n",
       "       [     1.  ,  78389.47, 299737.29],\n",
       "       [     1.  ,  73994.56, 303319.26],\n",
       "       [     1.  ,  67532.53, 304768.73],\n",
       "       [     1.  ,  77044.01, 140574.81],\n",
       "       [     1.  ,  64664.71, 137962.62],\n",
       "       [     1.  ,  75328.87, 134050.07],\n",
       "       [     1.  ,  72107.6 , 353183.81],\n",
       "       [     1.  ,  66051.52, 118148.2 ],\n",
       "       [     1.  ,  65605.48, 107138.38],\n",
       "       [     1.  ,  61994.48,  91131.24],\n",
       "       [     1.  ,  61136.38,  88218.23],\n",
       "       [     1.  ,  63408.86,  46085.25],\n",
       "       [     1.  ,  55493.95, 214634.81],\n",
       "       [     1.  ,  46426.07, 210797.67],\n",
       "       [     1.  ,  46014.02, 205517.64],\n",
       "       [     1.  ,  28663.76, 201126.82],\n",
       "       [     1.  ,  44069.95, 197029.42],\n",
       "       [     1.  ,  20229.59, 185265.1 ],\n",
       "       [     1.  ,  38558.51, 174999.3 ],\n",
       "       [     1.  ,  28754.33, 172795.67],\n",
       "       [     1.  ,  27892.92, 164470.71],\n",
       "       [     1.  ,  23640.93, 148001.11],\n",
       "       [     1.  ,  15505.73,  35534.17],\n",
       "       [     1.  ,  22177.74,  28334.72],\n",
       "       [     1.  ,   1000.23,   1903.93],\n",
       "       [     1.  ,   1315.46, 297114.46],\n",
       "       [     1.  ,      0.  ,      0.  ],\n",
       "       [     1.  ,    542.05,      0.  ],\n",
       "       [     1.  ,      0.  ,  45173.06]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
